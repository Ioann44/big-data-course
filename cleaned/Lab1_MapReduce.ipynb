{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p style=\"text-align: center;\">МИНИСТЕРСТВО ОБРАЗОВАНИЯ И НАУКИ\n",
    "\n",
    " РОССИЙСКОЙ ФЕДЕРАЦИИ\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">Федеральное государственное автономное\n",
    "\n",
    " образовательное учреждение высшего образования\n",
    "\n",
    " «Самарский национальный исследовательский университет\n",
    "\n",
    " имени академика С. П. Королева»\n",
    "\n",
    " (Самарский университет)</p>\n",
    "\n",
    " <br>\n",
    "\n",
    " <br>\n",
    "\n",
    " <br>\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">Институт информатики и кибернетики\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">Факультет информатики\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">Кафедра программных систем\n",
    "\n",
    "\n",
    "\n",
    "  <br><br><br>\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">ОТЧЁТ\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">по лабораторной работе № 1\n",
    "\n",
    " <p style=\"text-align: center;\">«Введение в модель MapReduce»\n",
    "\n",
    " <p style=\"text-align: center;\">по курсу «Интеллектуальный анализ данных и большие данные»\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">\n",
    "\n",
    " <br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: right;\">Выполнил: Яшин И.А.\n",
    "\n",
    " <p style=\"text-align: right;\">гр. 6132-020402D\n",
    "\n",
    " <p style=\"text-align: right;\">\n",
    "\n",
    " <br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " <p style=\"text-align: center;\">Самара 2025\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Введение в модель MapReduce на Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple # requires python 3.6+\n",
    "from typing import Iterator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Модель элемента данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(NamedTuple):\n",
    "  id: int\n",
    "  age: int\n",
    "  social_contacts: int\n",
    "  gender: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(_, row: User):\n",
    "    if row.gender == \"female\":\n",
    "        yield (row.age, row)\n",
    "\n",
    "\n",
    "def REDUCE(age: str, rows: Iterator[User]):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in rows:\n",
    "        sum += row.social_contacts\n",
    "        count += 1\n",
    "    if count > 0:\n",
    "        yield (age, sum / count)\n",
    "    else:\n",
    "        yield (age, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Функция RECORDREADER моделирует чтение элементов с диска или по сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RECORDREADER():\n",
    "  return [(u.id, u) for u in input_collection]\n",
    "\n",
    "RECORDREADER()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "def flatten_deprecated(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "flatten = chain.from_iterable\n",
    "assert list(flatten_deprecated([[1, 2], [3, 4]])) == list(flatten([[1, 2], [3, 4]])) == [1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_output = flatten(map(lambda x: MAP(*x), RECORDREADER()))\n",
    "map_output = list(map_output) # materialize\n",
    "map_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def groupbykey_deprecated(iterable):\n",
    "    t = {}\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = defaultdict(list)\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2].append(v2)\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "assert (\n",
    "    list(groupbykey_deprecated([(1, \"a\"), (2, \"b\"), (2, \"c\")]))\n",
    "    == list(groupbykey([(1, \"a\"), (2, \"b\"), (2, \"c\")]))\n",
    "    == [(1, [\"a\"]), (2, [\"b\", \"c\"])]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_output = groupbykey(map_output)\n",
    "shuffle_output = list(shuffle_output)\n",
    "shuffle_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_output = flatten(map(lambda x: REDUCE(*x), shuffle_output))\n",
    "reduce_output = list(reduce_output)\n",
    "reduce_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Все действия одним конвейером!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER()))))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **MapReduce**\n",
    "\n",
    " Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель MapReduce, без учёта распределённого хранения данных.\n",
    "\n",
    "\n",
    "\n",
    " Пользователь для решения своей задачи реализует RECORDREADER, MAP, REDUCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "flatten = chain.from_iterable\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = defaultdict(list)\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2].append(v2)\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def MapReduce(RECORDREADER, MAP, REDUCE):\n",
    "    return flatten(map(lambda x: REDUCE(*x), groupbykey(flatten(map(lambda x: MAP(*x), RECORDREADER())))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Спецификация MapReduce\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    " f (k1, v1) -> (k2,v2)*\n",
    "\n",
    " g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "\n",
    "\n",
    " mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "\n",
    " groupby ((k2,v2)*) -> (k2,v2*)*\n",
    "\n",
    " flatten (e2**) -> e2*\n",
    "\n",
    "\n",
    "\n",
    " mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
    "\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple  # requires python 3.6+\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    age: int\n",
    "    social_contacts: int\n",
    "    gender: str\n",
    "\n",
    "\n",
    "input_collection = [\n",
    "    User(id=0, age=55, gender=\"male\", social_contacts=20),\n",
    "    User(id=1, age=25, gender=\"female\", social_contacts=240),\n",
    "    User(id=2, age=25, gender=\"female\", social_contacts=500),\n",
    "    User(id=3, age=33, gender=\"female\", social_contacts=800),\n",
    "]\n",
    "\n",
    "\n",
    "def MAP(_, row: User):\n",
    "    if row.gender == \"female\":\n",
    "        yield (row.age, row)\n",
    "\n",
    "\n",
    "def REDUCE(age: str, rows: Iterator[User]):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in rows:\n",
    "        sum += row.social_contacts\n",
    "        count += 1\n",
    "    if count > 0:\n",
    "        yield (age, sum / count)\n",
    "    else:\n",
    "        yield (age, 0)\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    return [(u.id, u) for u in input_collection]\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Matrix-Vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "mat = np.ones((5,4))\n",
    "vec = np.random.rand(4) # in-memory vector in all map tasks\n",
    "\n",
    "def MAP(coordinates:tuple[int, int], value:int):\n",
    "  i, j = coordinates\n",
    "  yield (i, value*vec[j])\n",
    " \n",
    "def REDUCE(i:int, products:Iterator[NamedTuple]):\n",
    "  sum = 0\n",
    "  for p in products:\n",
    "    sum += p\n",
    "  yield (i, sum)\n",
    "\n",
    "def RECORDREADER():\n",
    "  for i in range(mat.shape[0]):\n",
    "    for j in range(mat.shape[1]):\n",
    "      yield ((i, j), mat[i,j])\n",
    "      \n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"it is what it is\"\n",
    "d2 = \"what is it\"\n",
    "d3 = \"it is a banana\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    yield (str(docid), document)\n",
    "\n",
    "def MAP(docId:str, body:str):\n",
    "  for word in set(body.split(' ')):\n",
    "    yield (word, docId)\n",
    " \n",
    "def REDUCE(word:str, docIds:Iterator[str]):\n",
    "  yield (word, sorted(docIds))\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "def RECORDREADER():\n",
    "  for (docid, document) in enumerate(documents):\n",
    "    for (lineid, line) in enumerate(document.split('\\n')):\n",
    "      yield (f\"{docid}:{lineid}\", line)\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split(\" \"):  \n",
    "    yield (word, 1)\n",
    " \n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "output = list(output)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MapReduce Distributed\n",
    "\n",
    "\n",
    "\n",
    " Добавляется в модель фабрика RECORDREADER-ов --- INPUTFORMAT, функция распределения промежуточных результатов по партициям PARTITIONER, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def groupbykey(iterable):\n",
    "    t = {}\n",
    "    for k2, v2 in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def groupbykey_distributed(map_partitions, PARTITIONER):\n",
    "    global reducers\n",
    "    partitions = [dict() for _ in range(reducers)]\n",
    "    for map_partition in map_partitions:\n",
    "        for k2, v2 in map_partition:\n",
    "            p = partitions[PARTITIONER(k2)]\n",
    "            p[k2] = p.get(k2, []) + [v2]\n",
    "    return [\n",
    "        (partition_id, sorted(partition.items(), key=lambda x: x[0]))\n",
    "        for (partition_id, partition) in enumerate(partitions)\n",
    "    ]\n",
    "\n",
    "\n",
    "def PARTITIONER(obj):\n",
    "    global reducers\n",
    "    return hash(obj) % reducers\n",
    "\n",
    "\n",
    "def MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER=PARTITIONER, COMBINER=None):\n",
    "    map_partitions = (flatten((MAP(*k1v1) for k1v1 in record_reader)) for record_reader in INPUTFORMAT())\n",
    "    if COMBINER != None:\n",
    "        map_partitions = (\n",
    "            flatten((COMBINER(*k2v2) for k2v2 in groupbykey(map_partition))) for map_partition in map_partitions\n",
    "        )\n",
    "    reduce_partitions = groupbykey_distributed(map_partitions, PARTITIONER)  # shuffle\n",
    "    reduce_outputs = (\n",
    "        (reduce_partition[0], flatten((REDUCE(*reduce_input_group) for reduce_input_group in reduce_partition[1])))\n",
    "        for reduce_partition in reduce_partitions\n",
    "    )\n",
    "    sum_result = sum([len(vs) for (k, vs) in flatten([partition for (partition_id, partition) in reduce_partitions])])\n",
    "    print(f\"{sum_result} key-value pairs were sent over a network.\")\n",
    "    return reduce_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Спецификация MapReduce Distributed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    " f (k1, v1) -> (k2,v2)*\n",
    "\n",
    " g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "\n",
    "\n",
    " e1 (k1, v1)\n",
    "\n",
    " e2 (k2, v2)\n",
    "\n",
    " partition1 (k2, v2)*\n",
    "\n",
    " partition2 (k2, v2*)*\n",
    "\n",
    "\n",
    "\n",
    " flatmap (e1->e2*, e1*) -> partition1*\n",
    "\n",
    " groupby (partition1*) -> partition2*\n",
    "\n",
    "\n",
    "\n",
    " mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "\n",
    " mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
    "\n",
    " ```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3, d1, d2, d3]\n",
    "\n",
    "maps = 3\n",
    "reducers = 2\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "  \n",
    "  def RECORDREADER(split):\n",
    "    for (docid, document) in enumerate(split):\n",
    "      for (lineid, line) in enumerate(document.split()):\n",
    "        yield (\"{}:{}\".format(docid,lineid), line)\n",
    "      \n",
    "  split_size = int(np.ceil(len(documents)/maps))\n",
    "  for i in range(0, len(documents), split_size):\n",
    "    yield RECORDREADER(documents[i:i+split_size])\n",
    "\n",
    "def MAP(docId:str, line:str):\n",
    "  for word in line.split():  \n",
    "    yield (word, 1)\n",
    " \n",
    "def REDUCE(word:str, counts:Iterator[int]):\n",
    "  sum = 0\n",
    "  for c in counts:\n",
    "    sum += c\n",
    "  yield (word, sum)\n",
    "  \n",
    "# try to set COMBINER=REDUCE and look at the number of values sent over the network \n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None) \n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## TeraSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_values = np.random.rand(30)\n",
    "maps = 3\n",
    "reducers = 2\n",
    "min_value = 0.0\n",
    "max_value = 1.0\n",
    "\n",
    "def INPUTFORMAT():\n",
    "  global maps\n",
    "  \n",
    "  def RECORDREADER(split):\n",
    "    for value in split:\n",
    "        yield (value, None)\n",
    "      \n",
    "  split_size =  int(np.ceil(len(input_values)/maps))\n",
    "  for i in range(0, len(input_values), split_size):\n",
    "    yield RECORDREADER(input_values[i:i+split_size])\n",
    "    \n",
    "def MAP(value:int, _):\n",
    "  yield (value, None)\n",
    "  \n",
    "def PARTITIONER(key):\n",
    "  global reducers\n",
    "  global max_value\n",
    "  global min_value\n",
    "  bucket_size = (max_value-min_value)/reducers\n",
    "  bucket_id = 0\n",
    "  while((key>(bucket_id+1)*bucket_size) and ((bucket_id+1)*bucket_size<max_value)):\n",
    "    bucket_id += 1\n",
    "  return bucket_id\n",
    "\n",
    "def REDUCE(value:int, _):\n",
    "  yield (None,value)\n",
    "  \n",
    "partitioned_output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, COMBINER=None, PARTITIONER=PARTITIONER)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Упражнения\n",
    "\n",
    " Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
    "\n",
    "\n",
    "\n",
    " Для выполнения заданий переопределите функции RECORDREADER, MAP, REDUCE.\n",
    "\n",
    "\n",
    "\n",
    " Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Максимальное значение ряда\n",
    "\n",
    "\n",
    "\n",
    " Разработайте MapReduce алгоритм, который находит максимальное число входного списка чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lists = [np.random.randint(0, 50, 6) for _ in range(3)]\n",
    "print(\"Input\", *num_lists, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(num_lists):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: np.ndarray):\n",
    "    return ((list_id, num) for num in num_list)\n",
    "\n",
    "\n",
    "def REDUCE(list_id: int, numbers: Iterator):\n",
    "    yield (list_id, max(numbers).item())\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Арифметическое среднее\n",
    "\n",
    "\n",
    "\n",
    " Разработайте MapReduce алгоритм, который находит арифметическое среднее.\n",
    "\n",
    "\n",
    "\n",
    " $$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lists = [np.random.randint(0, 10, 4) for _ in range(3)]\n",
    "print(\"Input\", *num_lists, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(num_lists):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: np.ndarray):\n",
    "    return ((list_id, num) for num in num_list)\n",
    "\n",
    "\n",
    "def REDUCE(list_id: int, numbers: Iterator):\n",
    "    i = 0\n",
    "    total = np.int32()\n",
    "    for i, num in enumerate(numbers):\n",
    "        total += num\n",
    "    yield (list_id, total.item() / (i + 1))\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Drop duplicates (set construction, unique elements, distinct)\n",
    "\n",
    "\n",
    "\n",
    " Реализуйте распределённую операцию исключения дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [np.random.randint(0, 15, (4, 4)) for _ in range(3)]\n",
    "print(\"Input\", *sequences, sep=\"\\n\")\n",
    "\n",
    "reducers = 2\n",
    "def PARTITIONER(seq_id: int):\n",
    "    return int(seq_id >= 1)\n",
    "\n",
    "\n",
    "def INPUTFORMAT():\n",
    "    def RECORDREADER(seq_id, seq_parts: np.ndarray):\n",
    "        for part_id, part in enumerate(seq_parts):\n",
    "            yield ((seq_id, part_id), part)\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        yield RECORDREADER(i, seq)\n",
    "\n",
    "\n",
    "def MAP(id: tuple[int, int], num_list: np.ndarray):\n",
    "    return (((*id, num.item()), num) for num in num_list)\n",
    "\n",
    "\n",
    "def COMBINER(id: tuple[int, int, int], numbers: Iterator):\n",
    "    seq_id, part_id, num = id\n",
    "    yield (seq_id, num)  # multiple numbers in one line cuts here\n",
    "\n",
    "\n",
    "def REDUCE(seq_id: int, numbers: Iterator):\n",
    "    yield (seq_id, set(numbers))  # get rid of duplicates across rows\n",
    "\n",
    "\n",
    "output = MapReduceDistributed(INPUTFORMAT, MAP, REDUCE, PARTITIONER, COMBINER)\n",
    "print(\"Output\", *[(i, list(res)) for i, res in output], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Операторы реляционной алгебры\n",
    "\n",
    " ### Selection (Выборка)\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import random\n",
    "\n",
    "num_lists = [tuple(random.randint(0, 10) for _ in range(5)) for _ in range(6)]\n",
    "print(\"Input\", *num_lists, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def most_nums_are_even(seq: Sequence):\n",
    "    return sum(1 for num in seq if num % 2 == 0) * 2 >= len(seq)\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(num_lists):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: Sequence):\n",
    "    if most_nums_are_even(num_list):\n",
    "        yield (num_list, num_list)\n",
    "\n",
    "\n",
    "def REDUCE(numbers_key: int, numbers_value: Iterator):\n",
    "    yield (numbers_key, numbers_value)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Projection (Проекция)\n",
    "\n",
    "\n",
    "\n",
    " Проекция на множество атрибутов $S$.\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(random.randint(0, 10) for _ in range(10)) for _ in range(3)]\n",
    "S = set(range(6))\n",
    "print(\"Input\", *tuples, \"S\", S, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(tuples):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: Sequence):\n",
    "    for num in num_list:\n",
    "        if num in S:\n",
    "            yield (list_id, num)\n",
    "\n",
    "\n",
    "def REDUCE(list_id: int, numbers: Iterator):\n",
    "    yield (numbers, numbers)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Union (Объединение)\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(random.randint(0, 10) for _ in range(5)) for _ in range(2)]\n",
    "print(\"Input\", *tuples, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(tuples):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: Sequence):\n",
    "    for num in num_list:\n",
    "        yield (num, num)\n",
    "\n",
    "\n",
    "def REDUCE(num: int, numbers: Iterator):\n",
    "    yield (num, num)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", [k for k, _ in output], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Intersection (Пересечение)\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUPLES_NUM = 2\n",
    "tuples = [random.sample(range(0, 10), 5) for _ in range(TUPLES_NUM)]\n",
    "print(\"Input\", *tuples, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for list_id, num_list in enumerate(tuples):\n",
    "        yield (list_id, num_list)\n",
    "\n",
    "\n",
    "def MAP(list_id: int, num_list: Sequence):\n",
    "    for num in num_list:\n",
    "        yield (num, num)\n",
    "\n",
    "\n",
    "def REDUCE(num: int, numbers: Iterator):\n",
    "    if sum(1 for _ in numbers) == TUPLES_NUM:\n",
    "        yield (num, num)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", [k for k, _ in output], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Difference (Разница)\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, S = [random.sample(range(0, 10), 5) for _ in range(2)]\n",
    "print(\"Input\", R, S, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for is_R, num_list in zip((True, False), (R, S)):\n",
    "        yield (is_R, num_list)\n",
    "\n",
    "\n",
    "def MAP(is_R: bool, num_list: Sequence):\n",
    "    for num in num_list:\n",
    "        yield (num, is_R)\n",
    "\n",
    "\n",
    "def REDUCE(num: int, flags: Iterator):\n",
    "    is_R_occured = False\n",
    "    for is_R in flags:\n",
    "        if not is_R:\n",
    "            break\n",
    "        is_R_occured = True\n",
    "    else:\n",
    "        if is_R_occured:\n",
    "            yield (num, num)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", [k for k, _ in output], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Natural Join\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_values = random.sample(range(0, 10), 5)\n",
    "(*R,) = zip((random.randint(0, 50) for _ in range(5)), b_values)\n",
    "(*S,) = zip(b_values, (random.randint(0, 50) for _ in range(5)))\n",
    "random.shuffle(S)\n",
    "print(\"Input\", R, S, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for is_R, num_list in zip((True, False), (R, S)):\n",
    "        yield (is_R, num_list)\n",
    "\n",
    "\n",
    "def MAP(is_R: bool, paris_list: Sequence):\n",
    "    for pair in paris_list:\n",
    "        if is_R:\n",
    "            a, b = pair\n",
    "            yield (b, (True, a))\n",
    "        else:\n",
    "            b, c = pair\n",
    "            yield (b, (False, c))\n",
    "\n",
    "\n",
    "def REDUCE(b: int, pairs: Iterator[tuple[bool, int]]):\n",
    "    c, a = map(lambda pair: pair[1], sorted(pairs))\n",
    "    yield (a, b, c)\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Grouping and Aggregation (Группировка и аггрегация)\n",
    "\n",
    "\n",
    "\n",
    " **The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
    "\n",
    "\n",
    "\n",
    " **The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_list = [(random.randint(0,3), random.randint(0,50), random.randint(0,50)) for _ in range(5)]\n",
    "print(\"Input\", *triples_list, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def RECORDREADER():\n",
    "    for triple_id, triple in enumerate(triples_list):\n",
    "        yield (triple_id, triple)\n",
    "\n",
    "\n",
    "def MAP(triple_id: int, triple: tuple[int, ...]):\n",
    "    a, b, c = triple\n",
    "    yield (a, b)\n",
    "\n",
    "\n",
    "def REDUCE(a: int, b_list: list[int]):\n",
    "    yield (a, sum(b_list))\n",
    "\n",
    "\n",
    "output = MapReduce(RECORDREADER, MAP, REDUCE)\n",
    "print(\"Output\", *output, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Вычисление TF-IDF (Term Frequency – Inverse Document Fraquency)\n",
    "\n",
    "\n",
    "\n",
    " Реализуется в три этапа:\n",
    "\n",
    "\n",
    "\n",
    " **Этап 1:** Частота слова в документе\n",
    "\n",
    "\n",
    "\n",
    " **Этап 2:** Количество документов, в которых встречается слово\n",
    "\n",
    "\n",
    "\n",
    " **Этап 3:** Расчёт TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "import math\n",
    "from typing import cast\n",
    "\n",
    "# TO BROTHERS: текст нужно заменить на тот, который в примере в исходном файле. На момент моей работы, входных данных ещё не было\n",
    "source_text = \"\"\"Творчество наполняет жизнь яркими моментами и помогает выразить свои чувства и мысли\n",
    "Искусство вдохновляет нас на творчество и позволяет делиться своими чувствами с миром\n",
    "Вдохновение приходит от искусства и творчества наполняя нашу жизнь новыми идеями и эмоциями\n",
    "Эмоции рождающиеся в процессе творчества делают искусство живым и трогательным для каждого\n",
    "Жизнь полна эмоций и творчество помогает нам осознать эти эмоции через искусство и вдохновение\"\"\"\n",
    "# TO BROTHERS: в исходном тексте будут знаки препинания, их можно убрать кодом вроде следующего\n",
    "# sentence = \"\".join(filter(lambda char: char.isalnum() or char == \" \", sent_raw))\n",
    "docs = [line.split() for line in source_text.lower().split(\"\\n\")]\n",
    "print(\"Input\", source_text, sep=\"\\n\")\n",
    "\n",
    "def RECORDREADER():\n",
    "    for doc_id, words in enumerate(docs):\n",
    "        yield (doc_id, words)\n",
    "\n",
    "# TF\n",
    "def MAP_TF(doc_id, words):\n",
    "    words = list(words)\n",
    "    word_weight = 1 / len(words)\n",
    "    for word in words:\n",
    "        yield (doc_id, word), word_weight\n",
    "def REDUCE_TF(id: tuple[int, str], weights):\n",
    "    yield (id, sum(weights))\n",
    "type TF_TYPE = tuple[tuple[int, str], float]\n",
    "tf: Iterable[TF_TYPE] = MapReduce(RECORDREADER, MAP_TF, REDUCE_TF)\n",
    "\n",
    "# IDF\n",
    "def MAP_IDF(doc_id, words):\n",
    "    for word in words:\n",
    "        yield (word, doc_id)\n",
    "def REDUCE_IDF(word, doc_ids):\n",
    "    yield (word, math.log(len(docs) / len(set(doc_ids))))\n",
    "type IDF_TYPE = tuple[str, float]\n",
    "idf: Iterable[IDF_TYPE] = MapReduce(RECORDREADER, MAP_IDF, REDUCE_IDF)\n",
    "\n",
    "# TF-IDF\n",
    "def RECORDREADER_TFIDF():\n",
    "    # TO BROTHERS: вот тут вопрос, что можно было бы и не выделять 2 tf и idf в отдельные таблицы, а посчитать их в одном жирном запуске,\n",
    "    # и хранить вероятно с такими же флагами. Но мне не понравилось, т.к. что-то будет дублироваться, а в реальности всё усугубляется ещё и репликацией\n",
    "    # Ссылается на псевдокод со 2 лекции (не знаю что там)\n",
    "    for tfi in tf:\n",
    "        yield True, tfi  # is TF flag\n",
    "    for idfi in idf:\n",
    "        yield False, idfi\n",
    "def MAP_TFIDF(is_tf: bool, data):\n",
    "    if is_tf:\n",
    "        (doc_id, word), tf_data = cast(TF_TYPE, data)\n",
    "        yield (word, doc_id), tf_data\n",
    "    else:\n",
    "        word, idf_data = cast(IDF_TYPE, data)\n",
    "        for doc_id in range(len(docs)):\n",
    "            yield (word, doc_id), idf_data\n",
    "def REDUCE_TFIDF(word_doc, tf_idf):\n",
    "    muls = list(tf_idf)\n",
    "    yield (word_doc, muls[0]*muls[1] if len(muls) == 2 else 0)\n",
    "tfidf = MapReduce(RECORDREADER_TFIDF, MAP_TFIDF, REDUCE_TFIDF)\n",
    "print(\"Output\", *tfidf, sep=\"\\n\")\n",
    "# TO BROTHERS: вывод должен иметь группировку по документу (id дока), и в каждом вывести 5-10 слов с наивысшим tf-idf\n",
    "# если в решении от чата увидите itertools.groupby и sorted, скорее всего вы на правильном пути\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
