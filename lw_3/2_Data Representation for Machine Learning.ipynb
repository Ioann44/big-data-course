{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Представление и визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение — это создание моделей на основе данных: по этой причине мы начнем с обсуждения того, как данные могут быть представлены, чтобы их мог понять компьютер. Наряду с этим мы будем опираться на примеры matplotlib из предыдущего раздела и покажем несколько примеров визуализации данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные в библиотеке scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в scikit-learn, за очень немногими исключениями, хранятся в виде **двумерного массива** размером  `[n_samples, n_features]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n_samples:**  Количество образцов: каждый образец (выборка) представляет собой элемент для обработки (например, классификации). Образцом может быть документ, изображение, звук, видео, астрономический объект, строка в базе данных или файле CSV или что-то еще, что вы можете описать с помощью фиксированного набора количественных характеристик.\n",
    "- **n_features:**  Количество характеристик или отличительных признаков, которые можно использовать для количественного описания каждого элемента. Признаки обычно имеют вещественные значения, но в некоторых случаях могут иметь логические или дискретные значения.\n",
    "\n",
    "Количество признаков должно быть зафиксировано заранее. Однако их число может быть очень большим (например, миллионы признаков), причем большинство из них могут являться нулями для данной выборки. Это тот случай, когда матрицы `scipy.sparse` могут быть полезны, поскольку они гораздо эффективнее используют память, чем массивы numpy.\n",
    "\n",
    "Каждая выборка (точка данных) представляет собой строку в массиве данных, а каждый признак — это столбец."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой пример: Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера простого набора данных, хранящегося в scikit-learn. мы рассмотрим данные о цветках ирисов.\n",
    "Данные состоят из измерений трех разных видов ирисов. Существует три вида ирисов\n",
    "в наборе данных, которые отображены ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris Setosa\n",
    "<img src=\"figures/iris_setosa.jpg\" width=\"50%\">\n",
    "\n",
    "Iris Versicolor\n",
    "<img src=\"figures/iris_versicolor.jpg\" width=\"50%\">\n",
    "\n",
    "Iris Virginica\n",
    "<img src=\"figures/iris_virginica.jpg\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если мы хотим разработать алгоритм для распознавания видов ирисов, какими могут быть данные?**\n",
    "\n",
    "Помните: нам нужен двумерный массив размером `[n_samples x n_features]`.\n",
    "\n",
    "- На что будут ссылаться `n_samples`?\n",
    "\n",
    "- На что может ссылаться `n_features`?\n",
    "\n",
    "Помните, что для каждой выборки должно быть **фиксированное** количество признаков, а номер признака ``i`` должен быть одинаковым для каждой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим набор данных Iris Data из Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Scikit-learn есть базовый набор данных об этих видах ирисов. Данные содержат следующую информацию:\n",
    "\n",
    "Признаки набора данных Iris:\n",
    "\n",
    "  1. sepal length in cm (длина чашелистика в см)\n",
    "  2. sepal width in cm (ширина чашелистика в см)\n",
    "  3. petal length in cm (длина лепестка в см)\n",
    "  4. petal width in cm (ширина лепестка в см)\n",
    "   \n",
    "Целевые классы для прогнозирования:\n",
    "\n",
    "  1. Iris Setosa (Ирис Сетоза)\n",
    "  2. Iris Versicolour (Ирис разноцветный)\n",
    "  3. Iris Virginica (Ирис Вирджиния)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/petal_sepal.jpg\" alt=\"Sepal\" style=\"width: 50%;\"/>\n",
    "\n",
    "\"Petal-sepal\". Licensed under CC BY-SA 3.0 via Wikimedia Commons - https://commons.wikimedia.org/wiki/File:Petal-sepal.jpg#/media/File:Petal-sepal.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``scikit-learn`` содержит копию CSV-файла iris вместе со вспомогательной функцией для загрузки его в массивы numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результирующий набор данных представляет собой объект ``Bunch`` (т.е. словарь, который предоставляет свои ключи как атрибуты): можно посмотреть, что доступно, используя метод ``keys()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки для всех образцов хранятся в атрибуте ``data``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инормация о классе каждого образца хранится в атрибуте ``target``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.data.shape)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имена классов хранятся в атрибуте ``target_names``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти данные четырехмерны, но можно визуализировать два измерения одновременно, используя простую диаграмму рассеяния. Опять же, начнём с включения inline-режима matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = 2\n",
    "\n",
    "y_index = 0\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target, label=[0, 1, 2])\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "#plt.legend(loc=\"best\", title=\"Классы\", labels=[0, 1, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Быстрое упражнение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Измените** `x_index` **и** `y_index` **в вышерасположенном скрипте и  найдите комбинацию двух признаков, \n",
    "которые максимально разделяют три класса.**\n",
    "\n",
    "Это упражнение является предварительным анализом для процедуры **уменьшения размерности (dimensionality reduction)**, которая будет рассмотрена позднее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Другие доступные наборы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn предоставляет множество наборов данных для тестирования алгоритмов обучения. Они бывают трёх типов:\n",
    "\n",
    "- **Packaged Data:** Упакованные данные, эти небольшие наборы данных поставляются вместе с установкой scikit-learn и могут быть загружены с помощью инструментов в sklearn.datasets.load_*.\n",
    "- **Downloadable Data:** Загружаемые данные, эти большие наборы данных доступны для загрузки, а scikit-learn с использованием программных средств, которые упрощают этот процесс. Эти средства можно найти в ``sklearn.datasets.fetch_*``.\n",
    "- **Generated Data:** Сгенерированные данные, существует несколько наборов данных, которые генерируются на основе моделей с использованием случайного начального числа. Они доступны в ``sklearn.datasets.make_*``.\n",
    "\n",
    "Вы можете изучить доступные загрузчики, сборщики и генераторы наборов данных, используя функцию табуляции IPython. После импорта подмодуля наборов данных ``datasets`` из ``sklearn`` введите\n",
    "\n",
    "    datasets.load_<TAB>\n",
    "\n",
    "or\n",
    "\n",
    "    datasets.fetch_<TAB>\n",
    "\n",
    "or\n",
    "\n",
    "    datasets.make_<TAB>\n",
    "\n",
    "чтобы просмотреть список доступных функций.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаемые данные, использующие функции ``fetch_`` хранятся локально внутри подкаталога вашего домашнего каталога.\n",
    "within a subdirectory of your home directory.\n",
    "Можно использовать следующую функцию, чтобы определить полный путь к этому подкаталогу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import get_data_home\n",
    "get_data_home()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имейте в виду: многие из этих наборов данных довольно велики, и их загрузка может занять много времени!\n",
    "\n",
    "Если вы начинаете загрузку в блокноте IPython и хотите прервать ее, вы можете использовать функцию «прерывания ядра» ipython, доступную в меню или с помощью сочетания клавиш ``Ctrl-m i``.\n",
    "\n",
    "Вы можете нажать ``Ctrl-m h``, чтобы просмотреть список всех сочетаний клавиш для быстрого вызова команд ``ipython``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с файловыми данными \n",
    "\n",
    "Типичный набор данных содержит описание *n* объектов наблюдения, каждый из которых характеризуется заданным набором из *m* признаков. \n",
    "Таким образом, данные представляют собой некоторую матрицу *A* размером *n×m* . Элемент этой матрицы *A<sub>ij</sub>* является значением *j*-го признака *i*-го объекта наблюдения.  \n",
    "Наиболее распространённый вариант хранения/передачи данных, для обеспечения совместимости, использует текстовый формат представления данных. \n",
    "В этом случае данные хранятся в текстовом файле в виде таблицы, представленной в csv-формате (Comma-Separated Values). То есть в файле содержится *n* строк по *m* чисел (значений) в каждой строке, разделённых специальными знаками (разделителями). В качестве разделителей обычно используют запятые или точки с запятой. Каждая строка описывает признаки одного конкретного объекта наблюдения в некотором заданном порядке.  \n",
    "Первая строка может использоваться как заголовок, в котором содержатся названия признаков в том порядке, в котором они представлены в следующих *n* строках.  \n",
    "Каждая строка должна содержать одинаковое количество значений.  \n",
    "Нужно отметить, что в качестве разделителя целой и дробной части вещественных чисел может использоваться как точка, так и запятая в зависимости от локализации файла. \n",
    "Признаки могут быть представлены не только числами, но и в виде символьной информации.  \n",
    "Таким образом, при чтении файла данных необходимо учитывать следующее:\n",
    "- Символ разделителя.\n",
    "- Наличие заголовка в первой строке.\n",
    "- Формат представления вещественных чисел.\n",
    "- Использование признаков в символьном виде.\n",
    "- Возможное наличие специальных символов для обозначения отсутствующих значений.  \n",
    "  \n",
    "Рассмотрим различные случаи представления наборов данных в виде текстовых файлов.  \n",
    "1. Только числовые значения, вещественные и целые, без заголовка, разделитель – запятая.\n",
    "2. Первые четыре параметра – вещественные значения, пятый параметр – название класса, без заголовка, разделитель – запятая.\n",
    "3. Первые четыре параметра – вещественные значения, пятый параметр – название класса, первая строка – заголовок, разделитель – запятая.\n",
    "4. Первые четыре параметра – вещественные значения, пятый параметр – название класса, первая строка – заголовок, разделитель – точка с запятой.\n",
    "5. Первые четыре параметра – вещественные значения, пятый параметр – название класса, первая строка – заголовок, разделитель – запятая, некоторые значения параметров отсутствуют и указаны как символ \"?\".\n",
    "6. Первые четыре параметра – вещественные значения, пятый параметр – название класса, без заголовка, разделитель – пробел.\n",
    "  \n",
    "Для загрузки текстовых таблиц в массивы языка Python чаще всего используют две библиотеки – numpy и pandas.  \n",
    "В numpy чаще всего для чтения табличных данных используют функцию **genfromtxt**. Поскольку эта функция выполняет конвертирование в массив numpy в два прохода, то есть возможность обрабатывать отсутствующие значения в таблице. На первом проходе строки файла конвертируются в последовательность строк. На втором проходе каждая строка конвертируется в определённые значения таблицы.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим содержимое файла с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('iris.data')\n",
    "sss = f.read()\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем загрузить эти данные в массив *NumPy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris = np.genfromtxt('iris.data')\n",
    "print(iris.shape)\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть функция распознала, что в файле содержится 150 строк, но сами строки не распознаны в связи с отсутствием указания разделителя. По умолчанию в качестве разделителя предполагаются любые последовательные пробелы. Добавим в параметры функции параметр `delimiter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris = np.genfromtxt('iris.data', delimiter=',')\n",
    "print(iris.shape)\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем дополнительно формат столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris = np.genfromtxt('iris.data', delimiter=',', dtype=['f8','f8','f8','f8','U20'])\n",
    "print(iris.shape)\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А это не массив NumPy. Поэтому надо отдельно загрузить массив с данными и отдельно – массив с метками, сохраняя порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris_data = np.genfromtxt('iris.data', delimiter=',', usecols=(0,1,2,3))\n",
    "print(iris_data.shape)\n",
    "print(iris_data)\n",
    "\n",
    "iris_target = np.genfromtxt('iris.data', delimiter=',', dtype='U20', usecols=(4))\n",
    "print(iris_target.shape)\n",
    "iris_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и наконец, загрузим данные в массив NumPy, заменив метки-строки на числовые значения - индексы массива имён классов объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "convertfunc = lambda x: 0.0 if x.decode('utf-8') == iris_s[0] else 1. if x.decode('utf-8') == iris_s[1] else 2.0\n",
    "\n",
    "iris_s = list(dict.fromkeys(iris_target))  # формируем массив имён классов объектов, устраняя дубликаты из массива с метками\n",
    "print(iris_s)\n",
    "\n",
    "iris = np.genfromtxt('iris.data', delimiter=',', converters={4: convertfunc})\n",
    "print(iris.shape)\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convertfunc(x):\n",
    "    for i in range(0, len(iris_s)):\n",
    "        if x.decode('utf-8') == iris_s[i]: return float(i)\n",
    "\n",
    "iris_s = list(dict.fromkeys(iris_target))\n",
    "print(iris_s)\n",
    "\n",
    "iris = np.genfromtxt('iris.data', delimiter=',', converters={4: convertfunc})\n",
    "print(iris.shape)\n",
    "print(iris)\n",
    "print(iris_s[int(iris[67,4])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 3: Первые четыре параметра – вещественные значения, пятый параметр – название класса, *первая строка – заголовок*, разделитель – запятая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять посмотрим содержимое файла с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('iris3.data')\n",
    "sss = f.read()\n",
    "print(sss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для пропуска заголовка используется параметр `skip_header`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iris_data = np.genfromtxt('iris3.data', delimiter=',', skip_header=1, usecols=(0,1,2,3))\n",
    "print(iris_data.shape)\n",
    "print(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ввода табличных данных из файлов используется функции `read_csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "iris_df = pd.read_csv('iris3.data')\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные параметры функции `read_csv`:\n",
    "\n",
    "`header=None`\n",
    "\n",
    "`sep=';'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('iris.data', header=None)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование в *np-массив* и удаление столбца с именами классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('iris3.data')\n",
    "iris_df.values[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление столбца классов для объекта DataFrame выполняется несколько иначе. Используйте метод `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение 2\n",
    "\n",
    "1) Введите данные в массив NumPy из файла `iris5.data`. Найдите образцы с ошибками в параметрах и удалите их из набора.\n",
    "2) Введите данные в DataFrame из файла `iris5.data`. Найдите образцы с ошибками в параметрах и удалите их из набора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
