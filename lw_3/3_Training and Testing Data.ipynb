{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные для обучения и тестирования\n",
    "=====================================\n",
    "Чтобы оценить, насколько хорошо наши обучаемые модели обобщают, мы можем разделить наши данные на обучающий и тестовый наборы:\n",
    "\n",
    "<img src=\"figures/train_test_split.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если подумать о том, как обычно осуществляется машинное обучение, идея разделения обучения и тестирования имеет смысл. Системы реального мира обучаются на имеющихся у них данных, и по мере поступления других данных (от клиентов, датчиков или других источников) обученный классификатор должен прогнозировать результат на основе принципиально новых данных. Мы можем смоделировать это во время обучения, используя разделение обучение/тест: тестовые данные представляют собой симуляцию «будущих данных», которые поступят в систему во время реальной работы.\n",
    "\n",
    "Особенность набора iris в том, что метки в iris отсортированы, а это означает, что если мы разделим данные, используя пропорциональное разделение, мы получим все определенные метки (0 и 1) и очень мало других (2). Мы хотим разделить, как показано выше, но после того, как данные будут случайным образом перетасованы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить точную симуляцию реального мира, мы перетасуем наши данные, а затем разделим их. Используем генератор случайных чисел для формирования случайной последовательности индексов для перемешивания при копировании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "permutation = rng.permutation(len(X))\n",
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation\n",
    "X, y = X[permutation], y[permutation]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно разделить данные на обучающие и тестирующие. К счастью, это распространенный шаблон в машинном обучении, и в scikit-learn есть встроенная функция для разделения данных по этапам обучения и тестирования. Если доля  разделения не указана, то получаем 75% данных для обучения и 25% для тестирования. 80% и 20% — еще одно распространенное разделение, для указания распределения задаётся либо доля обучающих данных `train_size=0.8`, либо тестовых `test_size=0.2`. но здесь нет жестких правил. По умолчанию порядок образцов случайным образом перемешивается (если это не нужно, используйте параметр `shuffle=False`). Самое главное — честно оценить вашу систему на данных, которых она не видела во время обучения!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8)\n",
    "print(\"Labels for training and testing data\")\n",
    "print(train_y.shape, test_y.shape)\n",
    "print(train_y)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что данные ещё раз перетасовались!\n",
    "\n",
    "Оценивая производительность классификатора на данных, используемых во время обучения, можно получить ложную уверенность в правильности модели предсказания. Это может привести к запуску в эксплуатацию системы, которая не сможет предсказать новые данные! Гораздо лучше использовать разделение данных для обучения и тестирования, чтобы правильно увидеть, как обученная модель работает с новыми данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_X, train_y)\n",
    "pred_y = classifier.predict(test_X)\n",
    "print(\"Fraction Correct\")\n",
    "print(np.sum(pred_y == test_y) / float(len(test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем визуализировать правильные и неудавшиеся прогнозы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "correct_idx = np.where(pred_y == test_y)[0]\n",
    "print(correct_idx)\n",
    "incorrect_idx = np.where(pred_y != test_y)[0]\n",
    "print(incorrect_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two dimensions\n",
    "colors = [\"darkblue\", \"darkgreen\", \"gray\"]\n",
    "for n, color in enumerate(colors):\n",
    "    idx = np.where(test_y == n)[0]\n",
    "    plt.scatter(test_X[idx, 0], test_X[idx, 1], color=color, label=\"Class %s\" % str(n))\n",
    "plt.scatter(test_X[incorrect_idx, 0], test_X[incorrect_idx, 1], color=\"darkred\")\n",
    "# Make xlim larger to accommodate legend\n",
    "plt.xlim(3, 9)\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Iris Classification results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что ошибки возникают в области перекрытия зеленого (класс 1) и серого (класс 2). Это дает нам представление о том, какие признаки добавить — любой признак, который помогает разделить класс 1 и класс 2, должен улучшить производительность классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
