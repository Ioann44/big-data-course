{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация (Clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация — это задача объединения выборок в группы схожих выборок в соответствии с некоторой заранее определенной мерой сходства или несходства (например, на основе евклидова расстояния).\n",
    "В этом разделе мы рассмотрим базовую задачу кластеризации на некоторых синтетических и реальных наборах данных.\n",
    "\n",
    "Вот некоторые распространенные применения алгоритмов кластеризации:\n",
    "\n",
    "- Сжатие в смысле сокращения данных.\n",
    "- Использование в качестве этапа предварительной обработки для рекомендательных систем.\n",
    "- Например:\n",
    "    - группировка связанных веб-новостей (например, новостей Google) и результатов веб-поиска.\n",
    "    - группировка связанных котировок акций для управления инвестиционным портфелем\n",
    "    - составление профилей клиентов для анализа рынка.\n",
    "- Создание кодовой книги образцов прототипов для неконтролируемого извлечения признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с очень простого и очевидного примера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(random_state=42)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных явно присутствуют три отдельные группы точек, и мы хотели бы выделить их с помощью кластеризации.\n",
    "Даже если группы в данных очевидны, их трудно найти, когда данные находятся в многомерном пространстве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся одним из самых простых алгоритмов кластеризации — K-means.\n",
    "Это итерационный алгоритм, который ищет три центра кластера так, чтобы расстояние от каждой точки до центра ее кластера было минимальным.\n",
    "\n",
    "**Вопрос:** как будет выглядеть результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем получить метки кластеров либо вызвав `fit`, а затем обратившись к атрибуту `labels_` объекта KMeans, либо вызвав `fit_predict`. В любом случае результат содержит идентификатор кластера, которому назначена каждая точка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(labels == kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь нас, вероятно, устраивает кластеризация. Но в целом нам, возможно, захочется получить количественную оценку. Можно сравнить метки наших кластеров с фактическими данными, которые мы получили при генерации больших двоичных объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(accuracy_score(y, labels))\n",
    "print(confusion_matrix(y, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y == labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на то, что мы прекрасно восстановили разбиение данных на кластеры, назначенные нами идентификаторы кластеров были произвольными, и мы не можем надеяться на их повторяемость. Следовательно, необходимо использовать другую метрику оценки, например, ``adjusted_rand_score``, которая инвариантна к перестановкам меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(y, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Предположения кластеризации:** алгоритм кластеризации находит кластеры, делая предположения о том, что выборки должны быть сгруппированы вместе. Каждый алгоритм делает разные предположения, и качество и интерпретируемость ваших результатов будут зависеть от того, удовлетворяются ли эти предположения вашей цели. Для кластеризации K-средних модель заключается в том, что все кластеры имеют одинаковую сферическую дисперсию.\n",
    "\n",
    "**В общем, нет никакой гарантии, что структура, найденная алгоритмом кластеризации, имеет какое-либо отношение к тому, что вас интересовало.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем легко создать набор данных с неизотропными кластерами, на которых kmeans не сработает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=170, n_samples=600)\n",
    "rng = np.random.RandomState(74)\n",
    "\n",
    "transformation = rng.normal(size=(2, 2))\n",
    "X = np.dot(X, transformation)\n",
    "\n",
    "y_pred = KMeans(n_clusters=3, n_init=10).fit_predict(X)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Некоторые полезные процедуры кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведены несколько хорошо известных алгоритмов кластеризации. \n",
    "\n",
    "- `sklearn.cluster.KMeans`: <br/>\n",
    "    Самый простой, но эффективный алгоритм кластеризации. Необходимо заранее указать количество кластеров, и предполагается, что входные данные нормализованы (в качестве препроцессора используется модель PCA).\n",
    "- `sklearn.cluster.MeanShift`: <br/>\n",
    "    Может найти более привлекательные кластеры, чем KMeans, но не масштабируется для большого количества выборок.\n",
    "- `sklearn.cluster.DBSCAN`: <br/>\n",
    "    Может обнаруживать кластеры неправильной формы на основе компактности, т. е. разреженные области во входном пространстве, скорее всего, станут границами между кластерами. Также может обнаруживать выбросы (выборки, не являющиеся частью кластера).\n",
    "- `sklearn.cluster.AffinityPropagation`: <br/>\n",
    "    Алгоритм кластеризации, основанный на передаче сообщений между точками данных.\n",
    "- `sklearn.cluster.SpectralClustering`: <br/>\n",
    "    KMeans применяется к проекции лапласиана нормализованного графа: находит нормализованные разрезы графа, если матрица близости интерпретируется как матрица смежности графа.\n",
    "- `sklearn.cluster.Ward`: <br/>\n",
    "    Ward реализует иерархическую кластеризацию на основе алгоритма Уорда, подхода, минимизирующего дисперсию. На каждом шаге он минимизирует сумму квадратов разностей внутри всех кластеров (критерий инерции).\n",
    "\n",
    "Из них Ward, SpectralClustering, DBSCAN и метод распространения близости (affinity propagation) также могут работать с предварительно вычисленными матрицами сходства."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cluster_comparison.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упражнение\n",
    "============\n",
    "\n",
    "Для вышеиспользуемого набора данных с неизотропными кластерами, на которых kmeans не работает, найдите алгоритм кластеризации, который хорошо выделяет очевидные кластеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=170, n_samples=600)\n",
    "rng = np.random.RandomState(74)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
