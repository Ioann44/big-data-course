{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы визуализировать работу алгоритмов машинного обучения, часто бывает полезно изучить двумерные или одномерные данные, то есть данные, имеющие только один или два признака. Хотя на практике наборы данных обычно имеют гораздо больше признаков, при этом отображать многомерные данные на двумерных экранах достаточно сложно.\n",
    "\n",
    "Проиллюстрируем несколько очень простых примеров, прежде чем перейдем к более «реальным» наборам данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация  Classification\n",
    "========\n",
    "Сначала мы рассмотрим задачу классификации двух классов в двух измерениях. Мы используем синтетические данные, сгенерированные функцией `make_blobs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(centers=2, random_state=0)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[:5, :])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку данные двумерны, мы можем отобразить каждый образец как точку в двумерном пространстве, где первый признак — это ось X, а второй — ось Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40)\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку классификация — это задача обучения с учителем, и нас интересует, насколько хорошо модель обобщает, мы разделяем наши данные на обучающий набор для построения модели и тестового набора для оценки, насколько хорошо наша модель работает на новых данных. Функция `train_test_split` из модуля `model_selection` делает это за нас, случайным образом отделяя 25% данных для тестирования.\n",
    "\n",
    "<img src=\"figures/train_test_split.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scikit-learn estimator API\n",
    "<img src=\"figures/supervised_workflow.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый алгоритм представлен в scikit-learn через объект из соответствующего класса с родительским классом ''Estimator'' (Оценка).\n",
    "\n",
    "Например, логистическая регрессия реализуется через класс `LogisticRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все модели в scikit-learn имеют единый интерфейс с последовательным пошаговым применением методов.\n",
    "\n",
    "Сначала мы создаем экземпляр оценивающего класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы построить модель на основе наших данных, то есть научиться классифицировать новые точки, мы вызываем функцию `fit` («подгонки») с обучающими данными и соответствующими обучающими метками (желаемый результат для обучающей точки данных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы можем применить модель к неизвестным ей данным и использовать её для прогнозирования предполагаемого результата с помощью метода прогнозирования `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем сравнить их с реальными метками классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем оценить наш классификатор количественно, определив, какая часть прогнозов верна. Это называется оценкой **точности** (**accuracy**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует также удобная функция `score`, которую все классификаторы scikit-learn должны вычислять непосредственно на основе тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто бывает полезно сравнить эффективность обобщения (на тестовом наборе) с эффективностью на обучающем наборе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные средства оценивания результатов обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print (confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия — это так называемая линейная модель, а это означает, что создаётся решение, линейное во входном пространстве. В 2d это просто означает, что модель находит линию, отделяющую синие метки от красных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_separator(classifier, X, fill=False, line=True, ax=None, eps=None):\n",
    "    if eps is None:\n",
    "        eps = 1.0 #X.std() / 2.\n",
    "    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n",
    "    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n",
    "    xx = np.linspace(x_min, x_max, 100)\n",
    "    yy = np.linspace(y_min, y_max, 100)\n",
    "\n",
    "    X1, X2 = np.meshgrid(xx, yy)\n",
    "\n",
    "    X_grid = np.c_[X1.ravel(), X2.ravel()]\n",
    "\n",
    "    try:\n",
    "        decision_values = classifier.decision_function(X_grid)\n",
    "        levels = [0]\n",
    "        fill_levels = [decision_values.min(), 0, decision_values.max()]\n",
    "\n",
    "    except AttributeError:\n",
    "        # no decision_function\n",
    "        decision_values = classifier.predict_proba(X_grid)[:, 1]\n",
    "        levels = [.5]\n",
    "        fill_levels = [0, .5, 1]\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if fill:\n",
    "        ax.contourf(X1, X2, decision_values.reshape(X1.shape), levels=fill_levels, colors=['cyan', 'pink'])\n",
    "    if line:\n",
    "        ax.contour(X1, X2, decision_values.reshape(X1.shape), levels=levels, colors=\"black\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from figures import plot_2d_separator\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40)\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plot_2d_separator(classifier, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оценочные параметры**. Все расчетные параметры являются атрибутами объекта оценки, оканчивающимися знаком подчеркивания. Для логистической регрессии это коэффициенты и смещение линии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.coef_)\n",
    "print(classifier.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой классификатор: K Nearest Neighbors (K ближайших соседей).\n",
    "--------------------------------------------------\n",
    "Другой популярный и простой для понимания классификатор — K ближайших соседей K nearest neighbors (kNN). Он имеет одну из самых простых стратегий обучения: учитывая новое, неизвестное наблюдение, находятся среди других данных те наблюдения, которые имеют наиболее близкие признаки, и назначается преобладающий класс.\n",
    "\n",
    "Интерфейс точно такой же, как и для `LogisticRegression` рассмотреного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз используется параметр для KNeighborsClassifier, чтобы указать, что мы хотим просмотреть только одного ближайшего соседа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на обучающих данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40)\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plot_2d_separator(knn, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И посмотрим дополнительные средства оценивания результатов обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "knn_prediction = knn.predict(X_test)\n",
    "\n",
    "print (confusion_matrix(y_test, knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, knn_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать при обучении два соседа, три...\n",
    "\n",
    "Попробуйте изменить параметр `n_neighbors`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И ещё классификатор: Random Forest  (Случайное дерево).\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=2) #, n_estimators=100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf_prediction = clf.predict(X_test)\n",
    "print(classification_report(y_test, clf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40)\n",
    "plt.xlabel(\"first feature\")\n",
    "plt.ylabel(\"second feature\")\n",
    "plot_2d_separator(clf, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упражнение\n",
    "============\n",
    "Примените KNeighborsClassifier и/или RandomForestClassifier к набору данных `iris`. Поиграйте с разными значениями `n_neighbors` и понаблюдайте, как меняются результаты обучения и теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
