{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение без учителя (Unsupervised Learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во многих случаях обучения без учителя, такого как уменьшение размерности, обучение многообразию и извлечение признаков, находят новое представление входных данных без каких-либо дополнительных входных данных.\n",
    "\n",
    "<img src=\"figures/unsupervised_workflow.svg\" width=\"100%\">\n",
    "\n",
    "Самый простой пример этого, который едва ли можно назвать обучением, — это изменение масштаба данных для получения нулевого среднего значения и единичной дисперсии. Это полезный шаг предварительной обработки для многих моделей машинного обучения.\n",
    "\n",
    "Применение такой предварительной обработки имеет интерфейс, очень похожий на алгоритмы контролируемого обучения, которые мы видели до сих пор.\n",
    "\n",
    "Давайте загрузим набор данных iris и изменим его масштаб:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных iris не «центрирован», то есть имеет ненулевое среднее значение, а стандартное отклонение различно для каждого компонента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean : %s \" % X.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать какой-либо метод предварительной обработки, мы сначала импортируем оценщик, здесь `StandardScaler`, и создаем его экземпляр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с алгоритмами классификации и регрессии, вызываем «подгонку», чтобы изучить модель на основе данных. Поскольку это неконтролируемая модель, мы передаем только ``X``, без ``y``. \n",
    "\n",
    "Это просто оценивает среднее значение и стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можем масштабировать наши данные, применив метод `transform` вместо `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_scaled` имеет тоже количество образцов и признаков, но из каждого признака вычли среднее значение, и все признаки отмасштабированы для получения единичного стандартного отклонения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean : %s \" % X_scaled.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод главных компонент (Principal Component Analysis)\n",
    "============================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более интересное преобразование — это анализ главных компонент (PCA).\n",
    "Это метод уменьшения размерности данных путем создания линейной проекции.\n",
    "То есть мы находим новые признаки для представления данных, которые представляют собой линейную комбинацию старых данных (т. е. мы их вращаем).\n",
    "\n",
    "PCA находит эти новый базис путем поиска базиса с максимальной дисперсией.\n",
    "Обычно сохраняются лишь несколько компонентов, которые объясняют большую часть различий в данных. Чтобы проиллюстрировать, как может выглядеть вращение, мы сначала покажем его на двумерных данных и сохраним оба главных компонента.\n",
    "\n",
    "Мы создаем набор объектов с нормальным распределением признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(5)\n",
    "X_ = rnd.normal(size=(300, 2))\n",
    "X_blob = np.dot(X_, rnd.normal(size=(2, 2))) + rnd.normal(size=2)\n",
    "y = X_[:, 0] > 0\n",
    "plt.scatter(X_blob[:, 0], X_blob[:, 1], c=y, linewidths=0, s=30)\n",
    "plt.xlabel(\"feature 1\")\n",
    "plt.ylabel(\"feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как всегда, мы создаем экземпляр нашей модели PCA. По умолчанию все направления сохраняются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы подгоняем модель PCA к нашим данным. Поскольку PCA является неконтролируемым алгоритмом, выходной сигнал `y` отсутствует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем преобразовываем данные, спроецированные на главные компоненты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_blob)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, linewidths=0, s=30)\n",
    "plt.xlabel(\"first principal component\")\n",
    "plt.ylabel(\"second principal component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слева на графике вы можете увидеть четыре точки, которые раньше были сверху справа. PCA счел целесообразным, чтобы первый компонент располагался по диагонали, а второй - перпендикулярно ей. Поскольку PCA находит такое вращение, чтобы основные компоненты всегда находилисЬ под прямым углом друг к другу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снижение размерности для визуализации с помощью PCA\n",
    "--------------------------------------------------------------\n",
    "Рассмотрим набор данных digits. Его нельзя визуализировать на одном двумерном графике, так как он содержит 64 признака. Мы собираемся извлечь 2 измерения для его визуализации, используя пример из sklearn-примеров [ссылка здесь](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figures.plot_digits_datasets import digits_plot\n",
    "\n",
    "digits_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что эта проекция была определена *без* какой-либо информации о метках (представленных цветами): в этом смысле это **обучение без учителя**, то есть является **неконтролируемым**. Тем не менее, мы видим, что проекция дает нам представление о распределении различных цифр в пространстве параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold Learning (Обучение многообразиям)\n",
    "\n",
    "Одной из слабых сторон PCA является то, что он не может обнаружить нелинейные признаки. Набор\n",
    "алгоритмов, известных как *Manifold Learning*, был разработан для устранения\n",
    "этого недостатка. Канонический набор данных, используемый в Manifold learning, — это\n",
    "*S-кривая*, которую мы кратко рассмотрели в предыдущем разделе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_s_curve\n",
    "X, y = make_s_curve(n_samples=1000)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter3D(X[:, 0], X[:, 1], X[:, 2], c=y)\n",
    "ax.view_init(10, -60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это двумерный набор данных, встроенный в три измерения, но он встроен таким образом, что PCA не может обнаружить базовую ориентацию данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако алгоритмы обучения многообразиям, доступные в подмодуле ``sklearn.manifold``, способны восстановить базовое двумерное многообразие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "iso = Isomap(n_neighbors=15, n_components=2)\n",
    "X_iso = iso.fit_transform(X)\n",
    "plt.scatter(X_iso[:, 0], X_iso[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение\n",
    "Сравните результаты Isomap и PCA на 5-классовом подмножестве набора данных цифр (``load_digits(5)``).\n",
    "\n",
    "__Бонус__: Также сравните с t-SNE, еще одним популярным методом обучения многообразиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits(n_class=5)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
